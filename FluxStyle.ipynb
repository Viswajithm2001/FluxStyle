{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M4WysyZ5E2C"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# 1Ô∏è‚É£ Install Required Packages\n",
        "# ----------------------------\n",
        "\n",
        "# Core PyTorch framework for AI models\n",
        "!pip install torch torchvision torchaudio --quiet\n",
        "\n",
        "# Hugging Face diffusers + transformers for AI pipelines\n",
        "!pip install diffusers transformers accelerate --quiet\n",
        "\n",
        "# Gradio for interactive demo UI\n",
        "!pip install gradio --quiet\n",
        "\n",
        "# Efficient handling of model weights\n",
        "!pip install safetensors --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 2Ô∏è‚É£ Import Required Libraries\n",
        "# ----------------------------\n",
        "import torch                    # Core AI framework\n",
        "from diffusers import DiffusionPipeline  # FLUX.1 Kontext pipeline\n",
        "from PIL import Image           # Image handling\n",
        "import gradio as gr             # Interactive demo UI"
      ],
      "metadata": {
        "id": "tACvVo2669o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Paste your token inside the quotes\n",
        "login(token=\"key\")\n"
      ],
      "metadata": {
        "id": "X0IsX25dE_cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "model_id = \"black-forest-labs/FLUX.1-Kontext-dev\"\n",
        "# connect to any gpu model example T4 gpu to get proper output\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,  # ‚úÖ Correct parameter\n",
        ").to(\"cuda\")                 # Moves model to GPU\n",
        "\n"
      ],
      "metadata": {
        "id": "awtnvGnIRQ5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üé® Generate image from prompt\n",
        "prompt = \"A futuristic cityscape at sunset with flying cars\"\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "# üíæ Save output\n",
        "image.save(\"output.png\")\n"
      ],
      "metadata": {
        "id": "Xfkkh4xQQTiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üé® Function to generate images\n",
        "def generate_image(prompt: str):\n",
        "    image = pipe(prompt).images[0]\n",
        "    return image\n",
        "\n",
        "# üéõÔ∏è Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=generate_image,\n",
        "    inputs=gr.Textbox(label=\"Enter your prompt\"),\n",
        "    outputs=gr.Image(type=\"pil\", label=\"Generated Image\"),\n",
        "    title=\"FLUX.1 Image Generator\",\n",
        "    description=\"Generate images using the FLUX.1-Kontext model (via Hugging Face Diffusers).\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "id": "3ut2SbFeQvK1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
